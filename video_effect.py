import cv2
import mediapipe as mp
import numpy as np

# --- Khá»Ÿi táº¡o Mediapipe ---
mp_selfie_segmentation = mp.solutions.selfie_segmentation
segment = mp_selfie_segmentation.SelfieSegmentation(model_selection=1)

# --- Video input/output ---
input_path = "video_sample.mp4"
output_path = "output_effect.mp4"

cap = cv2.VideoCapture(input_path)
if not cap.isOpened():
    print("KhÃ´ng má»Ÿ Ä‘Æ°á»£c video!")
    exit()

width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
fps    = cap.get(cv2.CAP_PROP_FPS) or 30.0

out = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (width, height))

# --- Cáº¥u hÃ¬nh viá»n trÃ²n ---
max_radius = 2000       # bÃ¡n kÃ­nh lá»›n nháº¥t
radius_step = 40        # tá»‘c Ä‘á»™ lan tá»a má»—i frame
circle_color = (0, 140, 255)  # mÃ u cam BGR
thickness = 8           # Ä‘á»™ dÃ y viá»n

# --- XÃ¡c Ä‘á»‹nh vá»‹ trÃ­ ngÆ°á»i ---
ret, frame = cap.read()
if not ret:
    print("KhÃ´ng Ä‘á»c Ä‘Æ°á»£c video!")
    exit()

frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
result = segment.process(frame_rgb)
mask_init = (result.segmentation_mask > 0.3).astype(np.uint8) * 255

ys, xs = np.where(mask_init > 0)
if len(xs) == 0 or len(ys) == 0:
    print("KhÃ´ng phÃ¡t hiá»‡n Ä‘Æ°á»£c ngÆ°á»i trong khung hÃ¬nh")
    exit()

x_center = int(np.mean(xs))
y_top = int(np.min(ys))
y_bottom = int(np.max(ys))
y_chest = int(y_top + 0.5 * (y_bottom - y_top))
center = (x_center, y_chest)

cap.set(cv2.CAP_PROP_POS_FRAMES, 0)

current_radius = 0
radius_growing = True

# --- Xá»­ lÃ½ tá»«ng frame ---
while True:
    ret, frame = cap.read()
    if not ret:
        break

    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    result = segment.process(frame_rgb)
    mask_person = (result.segmentation_mask > 0.3).astype(np.uint8) * 255

    # --- Táº¡o viá»n "Ä‘iá»‡n giáº­t" hÃ¬nh chá»¯ nháº­t dá»c ---
    rect_mask = np.zeros((height, width), dtype=np.uint8)

    # KÃ­ch thÆ°á»›c cÆ¡ báº£n cá»§a khung Ä‘iá»‡n giáº­t
    rect_width = int(20000)   # Ä‘iá»u chá»‰nh tá»· lá»‡ chiá»u ngang
    rect_height = int(current_radius * 1.6)  # Ä‘iá»u chá»‰nh tá»· lá»‡ chiá»u dá»c

    # Táº¡o mÃ©p chá»¯ nháº­t (4 cáº¡nh)
    amplitude = 15      # Ä‘á»™ rung Ä‘iá»‡n
    smoothness = 20     # máº­t Ä‘á»™ dao Ä‘á»™ng cáº¡nh
    phase = cv2.getTickCount() / cv2.getTickFrequency() * 4.0

    # Táº¡o cáº¡nh trÃªn & dÆ°á»›i
    x = np.linspace(-rect_width // 2, rect_width // 2, 200)
    noise_top = np.sin(x / 10 + phase) * amplitude + np.random.uniform(-5, 5, size=x.shape)
    noise_bottom = np.sin(x / 8 + phase + np.pi) * amplitude + np.random.uniform(-5, 5, size=x.shape)

    top_pts = np.stack((center[0] + x, center[1] - rect_height // 2 + noise_top), axis=1).astype(np.int32)
    bottom_pts = np.stack((center[0] + x, center[1] + rect_height // 2 + noise_bottom), axis=1).astype(np.int32)

    # Táº¡o cáº¡nh trÃ¡i & pháº£i
    y = np.linspace(-rect_height // 2, rect_height // 2, 200)
    noise_left = np.sin(y / 12 + phase) * amplitude + np.random.uniform(-5, 5, size=y.shape)
    noise_right = np.sin(y / 9 + phase + np.pi / 2) * amplitude + np.random.uniform(-5, 5, size=y.shape)

    left_pts = np.stack((center[0] - rect_width // 2 + noise_left, center[1] + y), axis=1).astype(np.int32)
    right_pts = np.stack((center[0] + rect_width // 2 + noise_right, center[1] + y), axis=1).astype(np.int32)

    # Gá»™p 4 cáº¡nh láº¡i thÃ nh khung Ä‘iá»‡n
    pts = np.concatenate([top_pts, right_pts, bottom_pts[::-1], left_pts[::-1]]).reshape((-1, 1, 2))

    # Váº½ viá»n Ä‘iá»‡n giáº­t
    cv2.polylines(rect_mask, [pts], isClosed=True, color=255, thickness=thickness, lineType=cv2.LINE_AA)

    # --- Giá»¯ pháº§n viá»n trÃªn ngÆ°á»i ---
    visible_ring = cv2.bitwise_and(rect_mask, mask_person)

    # --- Ãp mÃ u viá»n chÃ­nh ---
    frame_out = frame.copy()
    frame_out[visible_ring > 0] = circle_color

    # --- Glow (phÃ¡t sÃ¡ng cam/Ä‘á» máº¡nh) ---
    glow = cv2.GaussianBlur(visible_ring, (0, 0), 10)

    # Táº¡o mÃ u phÃ¡t sÃ¡ng Ä‘á»â€“cam tÃ¹y chá»‰nh
    glow_bgr = cv2.cvtColor(glow, cv2.COLOR_GRAY2BGR)
    glow_colored = np.zeros_like(glow_bgr)
    glow_colored[..., 2] = cv2.multiply(glow, 1.5)  
    glow_colored[..., 1] = cv2.multiply(glow, 0.7)  
    glow_colored[..., 0] = cv2.multiply(glow, 0.3)  

    # Giá»›i háº¡n glow chá»‰ trong vÃ¹ng ngÆ°á»i
    mask_glow = cv2.cvtColor(visible_ring, cv2.COLOR_GRAY2BGR)
    glow_colored = cv2.bitwise_and(glow_colored, mask_glow)

    # TÄƒng cÆ°á»ng Ä‘á»™ sÃ¡ng tá»•ng thá»ƒ
    frame_out = cv2.addWeighted(frame_out, 1.0, glow_colored, 0.9, 15)

    out.write(frame_out)

    # --- Cáº­p nháº­t bÃ¡n kÃ­nh ---
    if radius_growing:
        current_radius += radius_step
        if current_radius >= max_radius:
            current_radius = max_radius
            radius_growing = False

cap.release()
out.release()
segment.close()
print("ğŸ”¥ Video Ä‘Ã£ lÆ°u:", output_path)
